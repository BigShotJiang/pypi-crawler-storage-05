{
  "name": "gptqmodel",
  "version": "4.2.0",
  "summary": "Production ready LLM model compression/quantization toolkit with hw accelerated inference support for both cpu/gpu via HF, vLLM, and SGLang.",
  "author": "ModelCloud",
  "license": "Apache-2.0",
  "home_page": "https://github.com/ModelCloud/GPTQModel",
  "download_filename": "gptqmodel-4.2.0.tar.gz",
  "download_time": "2025-09-12T09:40:07.824208",
  "package_url": "https://pypi.org/project/gptqmodel/"
}